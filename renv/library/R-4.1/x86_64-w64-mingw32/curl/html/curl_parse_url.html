<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Normalizing URL parser</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for curl_parse_url {curl}"><tr><td>curl_parse_url {curl}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Normalizing URL parser</h2>

<h3>Description</h3>

<p>Interfaces the libcurl <a href="https://curl.se/libcurl/c/libcurl-url.html">URL parser</a>.
URLs are automatically normalized where possible, such as in the case of
relative paths or url-encoded queries (see examples).
When parsing hyperlinks from a HTML document, it is possible to set <code>baseurl</code>
to the location of the document itself such that relative links can be resolved.
</p>


<h3>Usage</h3>

<pre>
curl_parse_url(url, baseurl = NULL, decode = TRUE, params = TRUE)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>url</code></td>
<td>
<p>a character string of length one</p>
</td></tr>
<tr valign="top"><td><code>baseurl</code></td>
<td>
<p>use this as the parent if <code>url</code> may be a relative path</p>
</td></tr>
<tr valign="top"><td><code>decode</code></td>
<td>
<p>automatically <a href="../../curl/help/curl_escape.html">url-decode</a> output.
Set to <code>FALSE</code> to get output in url-encoded format.</p>
</td></tr>
<tr valign="top"><td><code>params</code></td>
<td>
<p>parse individual parameters assuming query is in <code>application/x-www-form-urlencoded</code> format.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A valid URL contains at least a scheme and a host, other pieces are optional.
If these are missing, the parser raises an error. Otherwise it returns
a list with the following elements:
</p>

<ul>
<li> <p><em>url</em>: the normalized input URL
</p>
</li>
<li> <p><em>scheme</em>: the protocol part before the <code style="white-space: pre;">://</code> (required)
</p>
</li>
<li> <p><em>host</em>: name of host without port (required)
</p>
</li>
<li> <p><em>port</em>: decimal between 0 and 65535
</p>
</li>
<li> <p><em>path</em>: normalized path up till the <code style="white-space: pre;">?</code> of the url
</p>
</li>
<li> <p><em>query</em>: search query: part between the <code style="white-space: pre;">?</code> and <code style="white-space: pre;">#</code> of the url. Use <code>params</code> below to get individual parameters from the query.
</p>
</li>
<li> <p><em>fragment</em>: the hash part after the <code style="white-space: pre;">#</code> of the url
</p>
</li>
<li> <p><em>user</em>: authentication username
</p>
</li>
<li> <p><em>password</em>: authentication password
</p>
</li>
<li> <p><em>params</em>: named vector with parameters from <code>query</code> if set
</p>
</li></ul>

<p>Each element above is either a string or <code>NULL</code>, except for <code>params</code> which
is always a character vector with the length equal to the number of parameters.
</p>
<p>Note that the <code>params</code> field is only usable if the <code>query</code> is in the usual
<code>application/x-www-form-urlencoded</code> format which is technically not part of
the RFC. Some services may use e.g. a json blob as the query, in which case
the parsed <code>params</code> field here can be ignored. There is no way for the parser
to automatically infer or validate the query format, this is up to the caller.
</p>
<p>For more details on the URL format see
<a href="https://datatracker.ietf.org/doc/html/rfc3986">rfc3986</a>
or the steps explained in the <a href="https://url.spec.whatwg.org/#concept-basic-url-parser">whatwg basic url parser</a>.
</p>
<p>On platforms that do not have a recent enough curl version (basically only
RHEL-8) the <a href="https://github.com/ada-url/ada">Ada URL</a> library is used as fallback.
Results should be identical, though curl has nicer error messages. This is
a temporary solution, we plan to remove the fallback when old systems are
no longer supported.
</p>


<h3>Examples</h3>

<pre>
url &lt;- "https://jerry:secret@google.com:888/foo/bar?test=123#bla"
curl_parse_url(url)

# Resolve relative links from a baseurl
curl_parse_url("/somelink", baseurl = url)

# Paths get normalized
curl_parse_url("https://foobar.com/foo/bar/../baz/../yolo")$url

# Also normalizes URL-encoding (these URLs are equivalent):
url1 &lt;- "https://ja.wikipedia.org/wiki/\u5bff\u53f8"
url2 &lt;- "https://ja.wikipedia.org/wiki/%e5%af%bf%e5%8f%b8"
curl_parse_url(url1)$path
curl_parse_url(url2)$path
curl_parse_url(url1, decode = FALSE)$path
curl_parse_url(url1, decode = FALSE)$path
</pre>

<hr /><div style="text-align: center;">[Package <em>curl</em> version 6.2.2 <a href="00Index.html">Index</a>]</div>
</body></html>
